{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN\n",
    "- (2014) Generative Adversarial Nets\n",
    "\n",
    "![gan_model_type](img/gan_model_type.png)\n",
    "\n",
    "## Abstract\n",
    "- GANs은 두 개의 신경망으로 구성\n",
    "- **생성 모델 (G) : 데이터의 분포를 학습하는 모델**\n",
    "- **감별 모델 (D) : 생성 모델 G or 훈련 데이터로부터 나왔을 확률 추정 감별 모델**\n",
    "- GAN의 배경 : 적대적 샘플에 취약, 신경망이 잘못된 결과를 산출하도록 의도적으로 조작시킨 입력값 이면 신경망이 전혀 다른 결과로 판정하기 때문에 구분하는 것에서 착안\n",
    "\n",
    "![GAN_Structure](img/GAN_Structure.png)\n",
    "\n",
    "<hr>\n",
    "\n",
    "## GAN 목표\n",
    "- 이미지 데이터의 **분포를 근사하게 뽑아낼 수 있는 모델 G**를 만드는 것\n",
    "- **가짜 결과(G Model)가 진짜(Training)와 구별되지 않을 때**까지 모델 향상\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN Model\n",
    "- Multilayer perceptron을 통해 두 모델 생성\n",
    "- model을 backpropagation과 dropout 알고리즘을 통해 학습\n",
    "- generative model로 부터 나오는 sample은 forward propagation으로 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## GAN 학습 방법 (Nets)\n",
    "- 1. Latent Vector Z가 들어옴 (Generator)\n",
    "    - latent feature(숨어있는 특징 – color, shape) 사용하여 학습\n",
    "- 2. Generator를 거쳐서 Fake image를 만들어내고, discriminator에서 loss를 구함\n",
    "- 3. Discriminator는 Fake image와 Real Image를 받아서 Fake image가 0으로, Real Image를 1로 학습\n",
    "    - 결론적으로는 Fake Image는 다 틀리고 (다 Real Image)라고 생각하고, 1/2로 쏠림\n",
    "\n",
    "## 학습 Training Tips\n",
    "- **discriminator를 트레이닝할 때 generator의 파라미터 값을 고정**\n",
    "- **generator를 트레이닝할 때는 discriminator의 파라미터 값을 고정**\n",
    "- discriminator와 generator는 각각 고정된 상대 네트워크의 결과값을 통해 학습\n",
    "- 이로 인해 generator가 반드시 학습해야 하는 gradient를 더 잘 반영할 수 있게 됨\n",
    "\n",
    "\n",
    "<hr>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN Value Function\n",
    "\n",
    "![gan_loss](img/gan_loss.PNG)\n",
    "\n",
    "- **동일한 함수를 사용, 모델별 다른 목적을 가짐, min-max game에 기반한 optimize 문제** \n",
    "\n",
    "- 수식 설명\n",
    "    - x는 실제 데이터, G(z)는 생성된 데이터\n",
    "    - 생성자(G)는 오른쪽식만 해당 (왼쪽 식은 G가 없어서 상수)\n",
    "    - 앞부분 : 원본데이터(p_data(x)) 에서 한개의 데이터인 x를 샘플링하고, D에 x를 넣었을 때의 평균 기댓값을 구하겟다. (원본데이터 기반)\n",
    "    - 뒷부분(생성자) : noise를 뽑을 수 있는 distribution p(z) 에서 z를 샘플링하고 그 노이즈를 생성자 G에 넣고, D에 넣어서 1을 뺀 뒤 log 취한 것 (가짜데이터 기반, 분포 기반)\n",
    "    \n",
    "- Value Function 설명\n",
    "    - max D : D model이 구분을 잘 한다면,\n",
    "        - D(x) = 1\n",
    "        - D(G(x)) = 0 이여야 되고,\n",
    "        - log(D(x)) 및 log(1-D(G(x)))는 무한대\n",
    "\n",
    "    - min G : generative model이 잘 생성한다면,\n",
    "        - D는 G(z)를 잘 구분하지 못하고,\n",
    "        - D(G(z)) = 1이 됨\n",
    "        - log(D(x))가 낮아지며, log(1-D(G(x)))= log(0) 따라서 - 무한대 \n",
    "\n",
    "\n",
    "## 기댓값(E) 란\n",
    "- 기댓값은 모든 사건에 대해 확률을 곱하면서 더하여 계산\n",
    "   - 이산확률변수(시그마), 연속확률변수 (적분)\n",
    "- 단순히 모든 데이터를 하나씩 확인하여 식에 대입한 뒤 평균 계산\n",
    "- 전자식\n",
    "  - 원본 데이터 분포에서의 샘플 x를 뽑아 logD(x)의 기댓값 계산\n",
    "- 후자식\n",
    "  - 노이즈 분포에서의 샘플 z를 뽑아 log(1-D(G(Z))의 기댓값 게산\n",
    "  \n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN 문제점\n",
    "- (1) discriminator가 너무 뛰어나, 0이나 1에 매우 가까운 gradient값을 반환하게 되어, generator가 gradient값을 제대로 반영하기 어려운 경우\n",
    "- (2) generator가 너무 뛰어나면 discriminator가 진짜 데이터를 가짜 데이터로 판단할 확률이 높아지는 경우\n",
    "- (3) 이러한 문제는 두 신경망의 학습률(learning rates)을 각각 설정하여 완화할 수 있다. 두 개의 신경망은 항상 비슷한 “학습 수준” 1을 유지해야 한다.\n",
    "- (4) 모드 붕괴 현상(Mode Collapsing) \n",
    "    - 생성기(Generator)와 판별기(Discriminator)를 번갈아 학습을 진행하다보니, 생성기가 특정한 클래스의 데이터만 생성하여 속이려는 경우가 발생\n",
    "    - 판별기는 생성된 데이터 클래스의 다양성이 부족함을 알고 이 경우 위조라고 판단하게 됨\n",
    "    - Mini-batch를 통해서 해결 / discriminator가 원본 데이터에 대한 class label을 출력에 포함시키어 생성기 성능 증대."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 참고문헌\n",
    "- https://leedakyeong.tistory.com/entry/%EB%85%BC%EB%AC%B8Generative-Adversarial-NetsGAN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
