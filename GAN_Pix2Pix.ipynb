{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pix2Pix\n",
    "- Paper : (2016)_Pix2Pix - Image-to-Image Translation with Conditional Adversarial Nets\n",
    "- Image to Image Mapping Network에서 Photo-realistic을 추구, GAN의 Adversarial Training을 통해 해결하고자 함\n",
    "    - ex) 윤곽만 보이는 도로 그림에서 사진을 만들어내기\n",
    "    - ex) 흑백사진에서 컬러사진을 만들어내기,\n",
    "    - ex) 위성사진에서 지도를 만들어내기,\n",
    "    - ex) 아침에 찍은 사진을 밤에 찍은 사진으로 만들기\n",
    "    - ex) 윤곽선 사진과 진짜 구두 사진을 가지고 새로운 구두 사진 생성\n",
    "\n",
    "<hr>\n",
    "\n",
    "## Pix2pix 요약 \n",
    "- 배경 : 컬러 영상은 누구나 쉽게 모을 수 있고, 이와 Pair를 이루는 흑백 영상은 간단히 만들 수 있음 (Gray화 하면 되니까)\n",
    "- Pair로 되 있는 Data(x, y)로 Training 하여, Image to Image Translation 모델을 만듬\n",
    "- U-Net, PatchGAN 등을 통한 성능 최적화\n",
    "- 영상 변환의 형태와 무관하게 범용적으로 적용할 수 있다는 것이 큰 장점 (기존엔 각각 모델 선택)\n",
    "\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Network vs GAN Network\n",
    "\n",
    "- 일반 CNN Network로 진행시 잘 안됨\n",
    "    - 이유 : 각 픽셀간의 차이를 Loss를 구하고 평균을 내어 진행할텐데, 전체 픽셀에 대한 관점이기 때문에 픽셀 값이 정확한 값을 추정하기 보다는 안전한 값으로 설정하고 넘어간다는 것\n",
    "    - **대부분의 CNN 방식은 L1, L2 Loss를 최소화 시키는 방식을 사용하기 때문에 변환할 영상의 결과가 사람이 보기에 그럴듯 하게 나올 수 있는 결과의 평균을 취하는 쪽으로 감. -> 영상이 선명하지 못하고 blur 해지는 경향이 있음**\n",
    "\n",
    "![pix2pix_try1_loss](img/pix2pix_try1_loss.png)\n",
    "\n",
    "![pix2pix_try1](img/pix2pix_try1.png)\n",
    "\n",
    "- GAN이 잘되는 이유\n",
    "    - Noise Distribution으로 부터 Data Distribution을 뽑아내는 Learning을 하기 때문\n",
    "    - GAN에 기반하기 때문에 Loss에 대한 학습을 통하여 보다 선명한 결과를 얻을 수 있음\n",
    "\n",
    "\n",
    "## Pix2pix 목적함수\n",
    "![pix2pix_loss](img/pix2pix_loss.png)\n",
    "- 1항, 2항을 Adversarial Loss라고 하며 GAN에서 쓰던 Loss를 사용한 것이 특징\n",
    "- 3항 Reconstruction Loss로서, 기존의 CNN기반 학습 방법에서 사용하던 Loss\n",
    "- cGAN Loss 뿐만 아니라 l1 Reconstrutction loss를 까지 함꼐 고려해줘야, 보다 선명한 이미지를 생성 가능.\n",
    "- **Pix2Pix는 pixel과 pixel간의 연관 관계(joint configuration)까지 고려한 structured loss 개념이 자동으로 적용되기 때문에 다른 이미지 변환 알고리즘들에 비해 비교적 좋은 결과를 얻을 수 있음**\n",
    "\n",
    "<hr>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 이미지 Training Pair\n",
    "- GAN의 Discriminator에 들어갈 때 Pair로 들어감\n",
    "\n",
    "![pix2pix_train](img/pix2pix_train.png)\n",
    "\n",
    "<hr>\n",
    "\n",
    "## Pix2pix Architecture\n",
    "- Generator Model (U-Net 구조)\n",
    "    - 입력과 출력의 Resolution을 동일하게 하기 위함\n",
    "    - 일반 Encoder-Decoder 구조가 아닌, U-Net 구조(Skip-connection 존재)를 사용하여 정보의 손실을 방지\n",
    "\n",
    "![pix2pix_unet](img/pix2pix_unet.png)\n",
    "\n",
    "- Discriminator Model (PatchGAN)\n",
    "    - 기존의 이미지 단위의 판별을 Patch단위로 해보자 (N x N 크기의 Pathch로 나누고 각각의 Patch에 Loss Back-propagation 반영. \n",
    "    - 좀더 Detail한 부분에서 Generator가 피드백을 받을 것으로 기대\n",
    "        - 계산량이 늘어나지만 실제 좀더 Detail이 살아나며, 70x70이 적당하다고 함\n",
    "    \n",
    "![pix2pix_architecture](img/pix2pix_architecture.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pix2pix Results\n",
    "\n",
    "#### 1) 항공사진\n",
    "- 지도 -> 항공사진 , 항공사진 -> 지도에 대해 사람들 실험\n",
    "    - 지도 -> 항공사진에 대한 실수를 매우 많이하며, Pix2Pix 의 L1 + cGAN 이 좋은 결과를 냄\n",
    "\n",
    "![pix2pix_result2_table](img/pix2pix_result2_table.png)\n",
    "    \n",
    "![pix2pix_result2](img/pix2pix_result2.png)\n",
    "\n",
    "\n",
    "#### 2) 일반 사물\n",
    "\n",
    "![pix2pix_result](img/pix2pix_result.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 참고문헌\n",
    "- http://blog.naver.com/PostView.nhn?blogId=laonple&logNo=221366130381&parentCategoryNo=&categoryNo=22&viewDate=&isShowPopularPosts=false&from=postView\n",
    "- https://taeoh-kim.github.io/blog/image2image/\n",
    "- https://wheemi1.wixsite.com/wheemi2018/post/%EB%85%BC%EB%AC%B8%EB%A6%AC%EB%B7%B0-pix2pix-image-to-imagetranslationwithconditionaladversarialnetworks-arxiv-1611-07004v2-1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
