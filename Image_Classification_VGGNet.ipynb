{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGGNet\n",
    "- Paper : Very deep convolutional networks for large-scale image recognition\n",
    "- ILSVRC 망의 깊이가 어떤 영향을 주는지 연구를 하기위해 개발 (2014 준우승)\n",
    "- **receptive field의 크기를 3x3으로 고정하고 깊이가 어떤 영향을 주는지 6개의 구조에 대해 실험**\n",
    "\n",
    "## VGGNet 구조 및 Architecture\n",
    "- 11layer(A), 13layer(B), 16layer(D), 19layer(E) 에 대해서 실험\n",
    "- Pooling layer\n",
    "    - Conv layer다음에 Max pooling이 적용되고, 총 5개의 max pooling layer로 구성\n",
    "    - Pooling연산은 2x2 size & stride 2로 구성\n",
    "- FC Layer\n",
    "    - FC(4096)-FC(4096)-FC(1000) 으로 이루어짐\n",
    "\n",
    "- 기타\n",
    "    - LRN은 VGGNet에서 실험했을때 성능향상에 도움이 안됬다\n",
    "    - Fully Connected layer에서 파라미터의 갯수가 엄청 많음\n",
    "    - 1x1이 적용되지만 차원은 그대로 유지하면서 ReLU를 이용한 추가적인 non-linearity를 확보하기 위함\n",
    "    - GoogleNet이나 NIN의 1x1 경우는 차원을 줄이기 위한 목적   \n",
    "\n",
    "![vggnet_table](img/vggnet_table.png)\n",
    "\n",
    "![vggnet16_19](img/vggnet16_19.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## VGGNet 주요 포인트\n",
    "- **(1) 모든 층에서 3x3 필터 사용** \n",
    "    - 3x3 필터는 left, right, up, down을 고려할 수 있는 최소한의 receptive field이다.\n",
    "    - 5x5 => 3x3 필터 2번 적용효과\n",
    "    - 7x7 => 3x3 필터 3번 적용효과\n",
    "    - 장점\n",
    "        - **top,down, left, right를 고려할 수 있는 3x3으로 연산하게 되면, 한번할걸 2번, 3번 한다는건 non-linearlity 한 ReLU를 더쓴다는 것이고, non-linear한 문제를 더 잘풀수 있게 됨**\n",
    "        - **7x7이나 5x5보다 parameter수가 줄어들게됨.**\n",
    "\n",
    "- **(2) Large Scale Image Recognition**\n",
    "    - Input Image는 224x224\n",
    "    - Preprocessing으로는 RGB Mean Value를 뺴주는 것만 적용\n",
    "    \n",
    "- **(3) Increasing Depth**\n",
    "    - 3x3을 이용한 Layer증대\n",
    "    \n",
    "![VGG_E](img/VGG_E.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## VGGNet 학습 특징\n",
    "- Deep net은 학습할 떄 vanishing / exploding gradient 문제로 학습이 어려워질 수 있는데, 이것을 먼저 11 layer의 비교적 간단한 구조 - A 를 학습시킨 후 더 깊은 나머지 구조 학습시에는 처음 4 layer와 마지막 fully-connected layrer의 경우 구조-A의 학습결과로 초기값 설정한 후 학습\n",
    "- **11-layer학습 후 해당 가중치를 초기값으로 이용했다는 것**\n",
    "- 해당 내용은 GoogleNet의 auxiliary classifer와 유사\n",
    "\n",
    "- 단점\n",
    "    - 메모리 사용량이 많다.\n",
    "\n",
    "![vgg_parameter](img/vgg_parameter.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 참고문헌\n",
    "- https://89douner.tistory.com/61?category=873854\n",
    "- https://bskyvision.com/504?category=635506"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
