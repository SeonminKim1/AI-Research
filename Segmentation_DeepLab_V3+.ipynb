{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepLab Series Paper\n",
    "- (2016)DeepLab_V1 - Semantic Image Segmentation with deep convolutional nets and fully connected crfs\n",
    "- (2017)DeepLab_V2 - DeepLab-Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs\n",
    "- (2017)DeepLab_V3 - Rethinking Atrous Convolution for Semantic Image Segmentation\n",
    "- (2018)DeepLab_V3+ - Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation\n",
    "\n",
    "## DeepLab-v1~v3+\n",
    "- DeepLab V1 : Atrous convolution을 처음 적용\n",
    "- DeepLab V2 : Multi-scale Image를 적용하기 위한 Atrous Spatial Pyramid Pooling (ASPP) 제안\n",
    "- DeepLab V3 : ResNet 구조에 Atrous Convolution을 활용한 좀 더 Dense한 feature map을 얻는 방법을 제안\n",
    "- DeepLab V3+ : Depthwise Separable Convolution과 Atrous Convolution을 결합한 Atrous Separable Convolution의 활용을 제안\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 주요개념 1. Atrous Convolution\n",
    "\n",
    "![astrous](img/astrous.png)\n",
    "- Atrous에서 trous는 구멍(hole)을 의미\n",
    "- Atrous Convolution은 기존 Convolution과 다르게 필터 내부에 빈 공간(parameter r)을 둔 채 작동\n",
    "- **기존 Convolution과 동일한 양의 파라미터와 계산량을 유지하면서 field of view(한 픽셀이 볼 수 있는 영역)을 크게 가져갈 수 있다**\n",
    "\n",
    "## 주요개념 2. ASPP(Atrous Spatial Pyramid Pooling)\n",
    "- DeepLab V2 에서 제안한 ASPP(Atrous Spatial Pyramid Pooling) 방법\n",
    "- Feature map을 rate가 다른 Atrous Convolution을 병렬로 적용한 뒤, 다시 합쳐주는 ASPP 기법 활용 제안\n",
    "- 유사(PSPNet의 Pyramid Pooling 기법)으로 multi-scale context를 모델 구조로 구현하여 보다 정확한 Semantic Segmentation을 수행하도록 도움.\n",
    "\n",
    "![deeplab_v3+_ASPP](img/deeplab_v3+_ASPP.png)\n",
    "\n",
    "\n",
    "## 주요개념 3. Depthwise separable convolution \n",
    "\n",
    "![deeplab_v3+_depthwise_separable_conv](img/deeplab_v3+_depthwise_separable_conv.png)\n",
    "\n",
    "- Deepthwise Separable Convolution을 통해 Convolution과 유사한 성능을 보이면서도 사용하는 **파라미터 수와 연산량을 획기적으로 줄임**\n",
    "\n",
    "\n",
    "## 주요개념 4. U-Net (decoder part)\n",
    "- U-Net의 Decoder 부분 사용\n",
    "\n",
    "![deeplab_v3+_unet](img/deeplab_v3+_unet.png)\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepLab v3 to v3+\n",
    "- **Encoder** : ResNet with Atrous Conv ==> **Xception으로 변경**\n",
    "- **ASPP** : ASPP 방법 ==> **ASSPP (Atrous Separable Spatial Pyramid Pooling)으로 변경**\n",
    "- **Decoder** : Bilinear Upsampling ==> **Simplified U-Net style decoder으로 변경**\n",
    "\n",
    "- Atrous Separable convolution 을 사용\n",
    "    - Down sampling, convolution upsampling 한것보다 더 효과가 좋았다.\n",
    "- Spatial pyramid pooling 사용 / U-Net 아이디어의 Concat 사용\n",
    "\n",
    "\n",
    "![deeplab_v3+_vs_v3](img/deeplab_v3+_vs_v3.png)\n",
    "\n",
    "## DeepLab v3+\n",
    "\n",
    "![deeplab_v3+](img/deeplab_v3+.png)\n",
    "\n",
    "\n",
    "- Encoder with Atrous Convolution \n",
    "    - Atrous convolution(AS을 통해 임의의 resolution으로 Feature map을 뽑아냄\n",
    "\n",
    "- Decoder\n",
    "    - 기존 V3에서는 단순 Bilinear upsampling\n",
    "    - V3+에서는 Encoder의 1x1 conv를 통해 Channel을 줄이고, bilinear upsamㅈpling 해준 후 concat\n",
    "    - ResNet Backbone보다, Xception Backbone이 더 좋았음\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully Connected CRF\n",
    "- CRF(Conditional Random Field)\n",
    "- 일반 DCNN 결과를 Bilinear interpolation을 통해 원영상 크기로 확대시 해상도가 떨어지는 문제 존재\n",
    "- CRF(Conditional Random Field)를 이용하여 post-processing을 수행\n",
    "\n",
    "![deeplab_v3+_crf](img/deeplab_v3+_crf.png)\n",
    "\n",
    "## Atrous Separable convolution\n",
    "- Expanding Receptive Field with hole convolution / Receptive field를 개선하기 위해 많이 나옴.\n",
    "- rate 라는 변수를 통해 더 많은 부분의 이미지를 보는 Receptive Field 보기 방식\n",
    "- Atrous Convolution을 활용함으로써 얻을 수 있는 이점은 기존 convolution과 동일한 양의 파라미터와 계산량을 유지하면서도, field of view(한 픽셀이 볼 수 있는 영역)를 크게 가져갈 수 있게 된다는 것\n",
    "\n",
    "![depthwise_pointwise_atrous_depthwise](img/depthwise_pointwise_atrous_depthwise.png)\n",
    "\n",
    "## Backbone\n",
    "- Xception의 Backbone으로 진행하였더니 더 좋았음.\n",
    "\n",
    "- 1) Atrous separable convolution을 적용하기 위해 모든 pooling operation을 depthwise separable convloution으로 대체.\n",
    "\n",
    "- 2) 각각의 3x3 depthwise convolution 이후에 추가적으로 batch normalization과 ReLU 활성화 함수를 추가 (오버피팅과 비선형적인 느낌 부여)\n",
    "\n",
    "<hr>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결과\n",
    "\n",
    "![deeplab_v3+_result](img/deeplab_v3+_result.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## DeepLab v3+ 요약\n",
    "- (1) Xception 기반의 encoder로 양질의 high level semantic 정보를 가지는 feature를 추출\n",
    "- (2) ASPP 모듈을 통해 각 픽셀이 여러 스케일의 context 정보를 취해 보다 정확한 추론이 가능\n",
    "- (3) U-Net 구조의 decoder를 통해(concat을 이용한 up-sampling방식) 각 물체에 해당하는 정교한 boundary를 그려낼 수 있다.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
