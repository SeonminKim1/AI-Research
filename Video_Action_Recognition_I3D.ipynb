{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video Action Recognition I3D\n",
    "- paper : (2017) Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action Classification Dataset 종류\n",
    "- 기존에는 UCF101, HMDB51 데이터셋이 존재\n",
    "- HMDB-51\n",
    "    - Action class : 51개\n",
    "    - 데이터 개수 : 6849개 / Youtube\n",
    "    - class 당 clip 개수 : 최소 101개\n",
    "    - https://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/ \n",
    "\n",
    "- UCF101 \n",
    "    - Action class : 101개\n",
    "    - 데이터 개수 : 13,320개 / Youtube\n",
    "    - class 당 clip 갯수 : 최소 100개 ~ 180개\n",
    "    - https://www.crcv.ucf.edu/data/UCF101.php \n",
    "\n",
    "- Kinetics 데이터셋\n",
    "    - Version : 400, 600, 700\n",
    "    - Action Class : 400개, 600개, 700개\n",
    "    - class 당 clip 개수 : 최소 250~1000개\n",
    "    - 데이터 갯수 30만 ~ 60만개\n",
    "    - 특징\n",
    "        - Deepmind사에서 만든 데이터셋, youtube url로 데이터셋 배포\n",
    "        - 클립당 10초 가량으로 이루어져 있으며 single class label이 달려있음\n",
    "        - 각 클립의 labeling은 사람이 했으며, 유튜브에 있는 유니크한 클립\n",
    "        - https://deepmind.com/research/open-source/kinetics\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction & Abstract\n",
    "- 새로운 Action Classification 데이터셋인 Kinetics을 만듬\n",
    "- Inflating 방법을 이용해 pre-trained 모델을 이용\n",
    "- Kinetics을 학습한 모델이 HMDB나 UCF에서도 좋은 성능을 보임\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Related Works\n",
    "\n",
    "![i3d_related_work](img/i3d_related_work.png)\n",
    "\n",
    "### The old 1. ConvNet + LSTM\n",
    "- sequntal한 video 데이터셋의 특성을 고려, RNN계열 LSTM 네트워크 추가\n",
    "- CNN을 이용해 프레임마다 feature를 추출 및 추출된 Feature Vector를 Decoder인 LSTM에 넣어주는 구조\n",
    "\n",
    "- 문제점\n",
    "    - temporal structure를 무시하는 구조\n",
    "    - low level motion 캡처 힘듬\n",
    "    - 여러 frame을 시간축으로 backpropagation하면서 unrolling 하기 때문에 학습비용 cost 가 높음\n",
    "    \n",
    "### The old 2 : 3D ConvNets\n",
    "- 3D Conv를 이용해 spatiotemporal 정보를 잘 취득\n",
    "- 학습해야할 파라미터가 많아 학습이 힘듬\n",
    "\n",
    "### The old 3 : Two-Stream Net\n",
    "- 입력으로 RGB 프레임과 optical flow 프레임을 같이 넣어주는 구조\n",
    "- RGB 만을 넣어주는 경우보다 거의 모든 경우 더 높은 성능을 보임\n",
    "\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Two-Stream Inflated 3D ConvNet\n",
    "- ImageNet을 학습한 2D ConvNet으로 문제 해결하고자 함\n",
    "\n",
    "### Inflating 방법\n",
    "- N x N filters를 N x N x N 필터로 바꾸는 방법을 지칭\n",
    "- 해당 가중치를 복제하여 필터의 dimension을 늘려준 뒤, weight를 1/N (갯수만큼)으로 나눔\n",
    "    \n",
    "![i3d_inflating](img/i3d_inflating.png)\n",
    "\n",
    "### Two 3D Streams\n",
    "- optical flow 정보를 넣어줌으로써 motion 정보에 대해 더 잘 예측\n",
    "- 두개의 I3D 모델을 각각 입력을 RGB, optical flow를 넣어주어 학습 진행\n",
    "- 두 Prediction의 평균값을 취해 최종 Prediction \n",
    "\n",
    "![i3d_inflated_inception_v1](img/i3d_inflated_inception_v1.png)\n",
    "\n",
    "![i3d_inflated_inception_module](img/i3d_inflated_inception_module.png)\n",
    "\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Training\n",
    "- ImageNet Pretrained Inception-v1 사용 가중치 Inflating\n",
    "- 모든 Conv layer에 BN, ReLU 사용\n",
    "- SGD + Momentum 0.9 사용\n",
    "- Augmentation\n",
    "    - 입력 영상 size : 256pixel, resize -> 224pixel, cropping\n",
    "    - 좌우 flip\n",
    "- 입력영상은 25fps, 총 길이는 64frame\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실험결과 (Results)\n",
    "\n",
    "![i3d_result2](img/i3d_result2.png)\n",
    "- 일반적으로 RGB만 넣어준 것보다, RGB, FLOW를 넣어준 것이 더 좋은 결과를 보임\n",
    "\n",
    "![i3d_result1](img/i3d_result1.png)\n",
    "- 처음부터 학습한 모델보다 , ImageNet pretrained를 사용한 모델의 성능이 더 잘나옴.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 참고문헌\n",
    "- https://chacha95.github.io/2019-07-04-VideoUnderstanding3/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
