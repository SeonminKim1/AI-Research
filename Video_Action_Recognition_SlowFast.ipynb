{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "161d0d0b",
   "metadata": {},
   "source": [
    "## Video Action Recognition C3D\n",
    "- Paper : (2014) https://arxiv.org/pdf/1412.0767.pdf\n",
    "    - Learning Spatiotemporal Features with 3D Convolutional Networks\n",
    "    \n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c0be49",
   "metadata": {},
   "source": [
    "## UCF 101 Dataset\n",
    "- Action class : 101개\n",
    "- 데이터 개수 : 13,320개 / Youtube\n",
    "- class 당 clip 갯수 : 최소 100개 ~ 180개\n",
    "- 크기 : (6.8G)\n",
    "- 특징 \n",
    "    - 다양한 camera motion과 object의 외형, 자세, viewpoint, 배경, illumination을 가짐\n",
    "    - 다운로드 링크\n",
    "        - https://www.crcv.ucf.edu/data/UCF101.php \n",
    "        \n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c809982",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Abstract & Introduction\n",
    "- 2D convoltuion이 Spatiotemporal 정보에 대해 잘 파악하지 못하는, 특성을 보완하기 위해 제안된 3D convolution 구조\n",
    "- 기존의 2D Conv 에서 3차원의 Conv을 이용하여 시공간적인 특징을 학습\n",
    "- 3x3x3 conv kernel 사용 C3D Model 만듬\n",
    "- 10개의 Layer만으로 UCF-101 52.8% 정확도 보임 (과거에는 더 낮았다고 함), 다른 벤치마크 성능들은 타 기술 대비 좋은 성능을 냄\n",
    "\n",
    "![c3d_past_vs_current](img/c3d_past_vs_current.png)\n",
    "\n",
    "- 지난 몇년간 이미지 conv를 통한 feature 학습에 많은 발전이 있었음 \n",
    "     -> **But, Video Base에는 Motion modeling이 부족**\n",
    "     -> **이를 3D Conv로 해결하고자 함**\n",
    "     -> 3D Conv는 Feature extracting과 Motion을 동시에 Modeling 가능\n",
    "\n",
    "## 2. 2D Conv -> 3D Conv Structure\n",
    "\n",
    "![c3d_3dconv_structure](img/c3d_3dconv_structure.png)\n",
    "\n",
    "- C3D는 3d conv와 3d pooling 덕에 temporal information을 더 잘 모델링 가능\n",
    "- (a) 일반적인 2D conv\n",
    "- (b) 복수의 이미지(Frame)에 2d적용 (다른 channel로 적용): 아웃풋은 image\n",
    "- (c) 3d conv에서 아웃풋이 volume형태\n",
    "\n",
    "![c3d_3dconv](img/c3d_3dconv.gif)\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a74741f",
   "metadata": {},
   "source": [
    "## 3. Exploring 3D ConvNet\n",
    "- 3D ConvNet 모델 설계를 위한 다양한 실험\n",
    "- UCF101 데이터셋을 이용하여 학습 및 실험\n",
    "- **Exploring kernel temporal depth**\n",
    "\n",
    "![c3d_depth](img/c3d_depth.png)\n",
    "\n",
    "- (1) 실험용 모델 정의\n",
    "    - input dimension (Video Clip)\n",
    "        - 3x16x128x171 (channel수, frame길이, height, width)\n",
    "        - Training 때는 random crops (3x16×112×112) 로 사용\n",
    "\n",
    "    - Conv Layer: 5개 (뒤에 pooling layer따라옴)\n",
    "        - 각 Layer 필터 수: 64, 128, 256, 512, 512\n",
    "        - **Kernel 사이즈 (d) : 실험적으로 여러 d 테스트**\n",
    "        - stride 1\n",
    "\n",
    "    - Pooling Layer: 5개\n",
    "        - max pooling, kernel size: 2x2x2, stride 1\n",
    "        - 첫번째 Pooling layer kernel size는 : 1x2x2 (temporal 신호를 일찍 합치지 않기 위해서)\n",
    "    - FC Layer: 2개 \n",
    "        - 2048 output\n",
    "    - Softmax Loss Layer\n",
    "\n",
    "- (2) 실험 방법\n",
    "    - kernel temporal depth d를 주로 변경하며 실험\n",
    "    - homogeneous temporal depth : 모든 conv layer가 같은 kernel temporal depth를 가짐\n",
    "    - d : 1,3,5,7 실험 (depth-d로 명명)\n",
    "        - depth-1는 각 프레임에 2d conv 적용한 것과 같음.\n",
    "        - 증가(increasing) : 3-3-5-5-7\n",
    "        - 감소(decreasing) : 7-5-5-3-3\n",
    "    \n",
    "- (3) 실험 결과\n",
    "    - UCF101에서 2d conv(d=1)인 경우가 가장 성능이 나빴고, 3x3x3이 가장 좋은 성능을 내었다\n",
    "    - UCF101은 중간규모였으니 이제 대규모에서 테스트\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c276f77",
   "metadata": {},
   "source": [
    "## 4. C3D Model \n",
    "- Spatiotemporal feature learning\n",
    "\n",
    "- Network Architecture (C3D Structure)\n",
    "    - 8conv, 5pooling, 2FC, softmax\n",
    "\n",
    "![c3d_model](img/c3d_model.png)\n",
    "\n",
    "\n",
    "- Datasets\n",
    "    - Sport-1M, 487 Sports categories, \n",
    "    - UCF 대비 클래스 5배, 데이터 100배\n",
    "    - Sports-1M은 긴 동영상이 많기 때문에 무작위로 추출 ( 2 초 길이 클립 5 개 씩)\n",
    "    \n",
    "- Training\n",
    "    - 128x171 -> 16x112x112 RESIZE, Croping\n",
    "    - horizontally flip, SGD, Learning rate 0.003\n",
    "    - I380K 데이터로 사전 훈련 된 모델에서 fine-tuning\n",
    "    \n",
    "- C3D는 무엇을 학습하는가?\n",
    "![c3d_visualization](img/c3d_visualization.png)\n",
    "\n",
    "- C3D는 초반 프레임에서는 외관에 초점, 점점 두드러지는 움직임을 추적\n",
    "- 그림은 두가지 conv5의 feature map을 시각화\n",
    "    - 1) 전체 사람(배경포함)에 초점 맞춘 후 나중엔 사람에게 초점\n",
    "    - 2) 먼저 눈에 초점 맞춘 후 화장시 주위에 일어나는 동작을 초점\n",
    "    - **따라서 C3D는 움직임과 외관 모두를 봄**\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acdf47f",
   "metadata": {},
   "source": [
    "## 5. Conclusion\n",
    "- Contribution\n",
    "    - 비디오 분석에서 3d conv가 시공간적 피쳐를 학습하는 것이 가능하며 Feature Extractor로서 3D Conv를 제안\n",
    "    - 3d Conv에 가장 가장 최적인 termporal kernel length를 찾기 위해, 커널 사이즈와 아키텍쳐에 대한 전반적인 조사\n",
    "    - 다른 비디오 분석 밴치마크에서 좋은 성능을 보임\n",
    "\n",
    "- 문제점\n",
    "    - long range temporal information에 대한 문제 (긴 시간에 대한 학습 잘 못함)\n",
    "    - C3D의 계산량 문제\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431fc0a9",
   "metadata": {},
   "source": [
    "## 참고문헌\n",
    "- https://chacha95.github.io/2019-07-02-VideoUnderstanding2/\n",
    "- https://22-22.tistory.com/74"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
